{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NB54koJNRUmB"
   },
   "source": [
    "https://huggingface.co/transformers/_modules/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28093,
     "status": "ok",
     "timestamp": 1619445968801,
     "user": {
      "displayName": "Ning Zhang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhRCnmT8mmairzuShAibDId7kDGmrCXjp8yIjrCOw=s64",
      "userId": "12536691088853738123"
     },
     "user_tz": -480
    },
    "id": "MyFzK7mFiW-6",
    "outputId": "cd4b882e-6d95-4609-f9e2-fbaf1728e5e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n",
      "/content/gdrive/My Drive/AI Sem II/NLP/Project Test/transformers-coqa-master\n",
      "/content/gdrive/My Drive/AI Sem II/NLP/Project Test/transformers-coqa-master\n"
     ]
    }
   ],
   "source": [
    "# For Google Colaboratory\n",
    " \n",
    "import sys, os\n",
    "if 'google.colab' in sys.modules:\n",
    "    # mount google drive\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/gdrive')\n",
    " \n",
    "    path_to_file = '/content/gdrive/My Drive/AI Sem II/NLP/Project Test'\n",
    "    print(path_to_file)\n",
    "    # change current path to the folder containing \"file_name\"\n",
    "    os.chdir(path_to_file)\n",
    "    !pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 66947,
     "status": "ok",
     "timestamp": 1619446007660,
     "user": {
      "displayName": "Ning Zhang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhRCnmT8mmairzuShAibDId7kDGmrCXjp8yIjrCOw=s64",
      "userId": "12536691088853738123"
     },
     "user_tz": -480
    },
    "id": "MYFgNG28jXnW",
    "outputId": "10d94bc2-61b0-4af3-91f6-85f80c62446e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/huggingface/transformers\n",
      "  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-4ptzcvau\n",
      "  Running command git clone -q https://github.com/huggingface/transformers /tmp/pip-req-build-4ptzcvau\n",
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.6.0.dev0) (20.9)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.6.0.dev0) (2.23.0)\n",
      "Collecting tokenizers<0.11,>=0.10.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/04/5b870f26a858552025a62f1649c20d29d2672c02ff3c3fb4c688ca46467a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3MB)\n",
      "\u001b[K     |████████████████████████████████| 3.3MB 13.0MB/s \n",
      "\u001b[?25hCollecting sacremoses\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
      "\u001b[K     |████████████████████████████████| 901kB 53.9MB/s \n",
      "\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers==4.6.0.dev0) (3.10.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.6.0.dev0) (1.19.5)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.6.0.dev0) (3.0.12)\n",
      "Collecting huggingface-hub>=0.0.8\n",
      "  Downloading https://files.pythonhosted.org/packages/a1/88/7b1e45720ecf59c6c6737ff332f41c955963090a18e72acbcbeac6b25e86/huggingface_hub-0.0.8-py3-none-any.whl\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.6.0.dev0) (2019.12.20)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.6.0.dev0) (4.41.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.6.0.dev0) (2.4.7)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.6.0.dev0) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.6.0.dev0) (2020.12.5)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.6.0.dev0) (1.24.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.6.0.dev0) (3.0.4)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.6.0.dev0) (7.1.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.6.0.dev0) (1.0.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.6.0.dev0) (1.15.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers==4.6.0.dev0) (3.7.4.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers==4.6.0.dev0) (3.4.1)\n",
      "Building wheels for collected packages: transformers\n",
      "  Building wheel for transformers (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for transformers: filename=transformers-4.6.0.dev0-cp37-none-any.whl size=2122482 sha256=fcc28d06f05e560853fcc473921b0b4e7a04b9ea2c44c41715d56bddb3765c1b\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-r14e3qu0/wheels/70/d3/52/b3fa4f8b8ef04167ac62e5bb2accb62ae764db2a378247490e\n",
      "Successfully built transformers\n",
      "Installing collected packages: tokenizers, sacremoses, huggingface-hub, transformers\n",
      "Successfully installed huggingface-hub-0.0.8 sacremoses-0.0.45 tokenizers-0.10.2 transformers-4.6.0.dev0\n",
      "Collecting spacy\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1b/d8/0361bbaf7a1ff56b44dca04dace54c82d63dad7475b7d25ea1baefafafb2/spacy-3.0.6-cp37-cp37m-manylinux2014_x86_64.whl (12.8MB)\n",
      "\u001b[K     |████████████████████████████████| 12.8MB 11.1MB/s \n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.8.2)\n",
      "Collecting srsly<3.0.0,>=2.4.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c3/84/dfdfc9f6f04f6b88207d96d9520b911e5fec0c67ff47a0dea31ab5429a1e/srsly-2.4.1-cp37-cp37m-manylinux2014_x86_64.whl (456kB)\n",
      "\u001b[K     |████████████████████████████████| 460kB 64.3MB/s \n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (56.0.0)\n",
      "Collecting thinc<8.1.0,>=8.0.3\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/61/87/decceba68a0c6ca356ddcb6aea8b2500e71d9bc187f148aae19b747b7d3c/thinc-8.0.3-cp37-cp37m-manylinux2014_x86_64.whl (1.1MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1MB 52.4MB/s \n",
      "\u001b[?25hCollecting spacy-legacy<3.1.0,>=3.0.4\n",
      "  Downloading https://files.pythonhosted.org/packages/8d/67/d4002a18e26bf29b17ab563ddb55232b445ab6a02f97bf17d1345ff34d3f/spacy_legacy-3.0.5-py2.py3-none-any.whl\n",
      "Requirement already satisfied, skipping upgrade: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.5)\n",
      "Requirement already satisfied, skipping upgrade: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (20.9)\n",
      "Requirement already satisfied, skipping upgrade: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.23.0)\n",
      "Requirement already satisfied, skipping upgrade: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.5)\n",
      "Collecting pydantic<1.8.0,>=1.7.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b3/0a/52ae1c659fc08f13dd7c0ae07b88e4f807ad83fb9954a59b0b0a3d1a8ab6/pydantic-1.7.3-cp37-cp37m-manylinux2014_x86_64.whl (9.1MB)\n",
      "\u001b[K     |████████████████████████████████| 9.1MB 53.3MB/s \n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: typing-extensions<4.0.0.0,>=3.7.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from spacy) (3.7.4.3)\n",
      "Collecting typer<0.4.0,>=0.3.0\n",
      "  Downloading https://files.pythonhosted.org/packages/90/34/d138832f6945432c638f32137e6c79a3b682f06a63c488dcfaca6b166c64/typer-0.3.2-py3-none-any.whl\n",
      "Collecting catalogue<2.1.0,>=2.0.3\n",
      "  Downloading https://files.pythonhosted.org/packages/82/a5/b5021c74c04cac35a27d34cbf3146d86eb8e173b4491888bc4908c4c8b3b/catalogue-2.0.3-py3-none-any.whl\n",
      "Requirement already satisfied, skipping upgrade: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.41.1)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.19.5)\n",
      "Requirement already satisfied, skipping upgrade: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.11.3)\n",
      "Collecting pathy>=0.3.5\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/87/5991d87be8ed60beb172b4062dbafef18b32fa559635a8e2b633c2974f85/pathy-0.5.2-py3-none-any.whl (42kB)\n",
      "\u001b[K     |████████████████████████████████| 51kB 7.5MB/s \n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.5)\n",
      "Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy) (2.4.7)\n",
      "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.12.5)\n",
      "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
      "Requirement already satisfied, skipping upgrade: click<7.2.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.4.0,>=0.3.0->spacy) (7.1.2)\n",
      "Requirement already satisfied, skipping upgrade: zipp>=0.5; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.3->spacy) (3.4.1)\n",
      "Requirement already satisfied, skipping upgrade: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy) (1.1.1)\n",
      "Collecting smart-open<4.0.0,>=2.2.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/11/9a/ba2d5f67f25e8d5bbf2fcec7a99b1e38428e83cb715f64dd179ca43a11bb/smart_open-3.0.0.tar.gz (113kB)\n",
      "\u001b[K     |████████████████████████████████| 122kB 53.5MB/s \n",
      "\u001b[?25hBuilding wheels for collected packages: smart-open\n",
      "  Building wheel for smart-open (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for smart-open: filename=smart_open-3.0.0-cp37-none-any.whl size=107098 sha256=e7aa2916c3278d90f31667c4c6cbd4e7ae342d89c78cbfb84af0e4212e8f5d33\n",
      "  Stored in directory: /root/.cache/pip/wheels/18/88/7c/f06dabd5e9cabe02d2269167bcacbbf9b47d0c0ff7d6ebcb78\n",
      "Successfully built smart-open\n",
      "Installing collected packages: catalogue, srsly, pydantic, thinc, spacy-legacy, typer, smart-open, pathy, spacy\n",
      "  Found existing installation: catalogue 1.0.0\n",
      "    Uninstalling catalogue-1.0.0:\n",
      "      Successfully uninstalled catalogue-1.0.0\n",
      "  Found existing installation: srsly 1.0.5\n",
      "    Uninstalling srsly-1.0.5:\n",
      "      Successfully uninstalled srsly-1.0.5\n",
      "  Found existing installation: thinc 7.4.0\n",
      "    Uninstalling thinc-7.4.0:\n",
      "      Successfully uninstalled thinc-7.4.0\n",
      "  Found existing installation: smart-open 5.0.0\n",
      "    Uninstalling smart-open-5.0.0:\n",
      "      Successfully uninstalled smart-open-5.0.0\n",
      "  Found existing installation: spacy 2.2.4\n",
      "    Uninstalling spacy-2.2.4:\n",
      "      Successfully uninstalled spacy-2.2.4\n",
      "Successfully installed catalogue-2.0.3 pathy-0.5.2 pydantic-1.7.3 smart-open-3.0.0 spacy-3.0.6 spacy-legacy-3.0.5 srsly-2.4.1 thinc-8.0.3 typer-0.3.2\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/huggingface/transformers\n",
    "!pip install -U spacy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 79606,
     "status": "ok",
     "timestamp": 1619446020324,
     "user": {
      "displayName": "Ning Zhang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhRCnmT8mmairzuShAibDId7kDGmrCXjp8yIjrCOw=s64",
      "userId": "12536691088853738123"
     },
     "user_tz": -480
    },
    "id": "W86G1qWTjwdc",
    "outputId": "e7e177f2-2c33-45ae-ff25-75fc80cfdbb9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;3m⚠ As of spaCy v3.0, shortcuts like 'en' are deprecated. Please use the\n",
      "full pipeline package name 'en_core_web_sm' instead.\u001b[0m\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import string\n",
    "import transformers\n",
    "import re\n",
    "from tqdm import tqdm, trange\n",
    "import spacy \n",
    "import spacy.cli\n",
    "import logging\n",
    "import collections\n",
    "from collections import Counter\n",
    "import math\n",
    "import torch\n",
    "from torch.utils.data import (DataLoader, RandomSampler, SequentialSampler, TensorDataset)\n",
    "from transformers import BertModel, BertTokenizer, AdamW\n",
    "#from pytorch_pretrained_bert.modeling import BertModel, BertPretrainedModel\n",
    "#from pytorch_pretrained_bert.tokenization import BertTokenizer\n",
    "#from pytorch_pretrained_bert.optimization import BertAdam, WarmupLinearSchedule\n",
    "#from pytorch_ptrtrained_bert.tokenization import BasicTokenizer, whitespace_tokenize\n",
    "from transformers.models.bert.tokenization_bert import BasicTokenizer\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import CrossEntropyLoss\n",
    "import json\n",
    "spacy.cli.download('en')\n",
    "spacy.load('en_core_web_sm')\n",
    "import random\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import matplotlib as pplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 81467,
     "status": "ok",
     "timestamp": 1619446022191,
     "user": {
      "displayName": "Ning Zhang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhRCnmT8mmairzuShAibDId7kDGmrCXjp8yIjrCOw=s64",
      "userId": "12536691088853738123"
     },
     "user_tz": -480
    },
    "id": "7kwXwuk3j0Sy",
    "outputId": "871e02e2-99be-4f0d-c501-ff674debad35"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentencepiece\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
      "\r",
      "\u001b[K     |▎                               | 10kB 18.9MB/s eta 0:00:01\r",
      "\u001b[K     |▌                               | 20kB 26.6MB/s eta 0:00:01\r",
      "\u001b[K     |▉                               | 30kB 31.7MB/s eta 0:00:01\r",
      "\u001b[K     |█                               | 40kB 22.4MB/s eta 0:00:01\r",
      "\u001b[K     |█▍                              | 51kB 15.9MB/s eta 0:00:01\r",
      "\u001b[K     |█▋                              | 61kB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |██                              | 71kB 12.7MB/s eta 0:00:01\r",
      "\u001b[K     |██▏                             | 81kB 13.6MB/s eta 0:00:01\r",
      "\u001b[K     |██▌                             | 92kB 13.3MB/s eta 0:00:01\r",
      "\u001b[K     |██▊                             | 102kB 12.8MB/s eta 0:00:01\r",
      "\u001b[K     |███                             | 112kB 12.8MB/s eta 0:00:01\r",
      "\u001b[K     |███▎                            | 122kB 12.8MB/s eta 0:00:01\r",
      "\u001b[K     |███▌                            | 133kB 12.8MB/s eta 0:00:01\r",
      "\u001b[K     |███▉                            | 143kB 12.8MB/s eta 0:00:01\r",
      "\u001b[K     |████                            | 153kB 12.8MB/s eta 0:00:01\r",
      "\u001b[K     |████▍                           | 163kB 12.8MB/s eta 0:00:01\r",
      "\u001b[K     |████▋                           | 174kB 12.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████                           | 184kB 12.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████▏                          | 194kB 12.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████▌                          | 204kB 12.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████▊                          | 215kB 12.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████                          | 225kB 12.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████▎                         | 235kB 12.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████▌                         | 245kB 12.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████▉                         | 256kB 12.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████                         | 266kB 12.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████▍                        | 276kB 12.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████▋                        | 286kB 12.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████                        | 296kB 12.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████▏                       | 307kB 12.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████▍                       | 317kB 12.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████▊                       | 327kB 12.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████                       | 337kB 12.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▎                      | 348kB 12.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▌                      | 358kB 12.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▉                      | 368kB 12.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████                      | 378kB 12.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▍                     | 389kB 12.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▋                     | 399kB 12.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████                     | 409kB 12.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▏                    | 419kB 12.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▍                    | 430kB 12.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▊                    | 440kB 12.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████                    | 450kB 12.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▎                   | 460kB 12.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▌                   | 471kB 12.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▉                   | 481kB 12.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████                   | 491kB 12.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▍                  | 501kB 12.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▋                  | 512kB 12.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▉                  | 522kB 12.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▏                 | 532kB 12.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▍                 | 542kB 12.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▊                 | 552kB 12.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████                 | 563kB 12.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▎                | 573kB 12.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▌                | 583kB 12.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▉                | 593kB 12.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████                | 604kB 12.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▍               | 614kB 12.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▋               | 624kB 12.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▉               | 634kB 12.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▏              | 645kB 12.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▍              | 655kB 12.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▊              | 665kB 12.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████              | 675kB 12.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▎             | 686kB 12.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▌             | 696kB 12.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▉             | 706kB 12.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████             | 716kB 12.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▎            | 727kB 12.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▋            | 737kB 12.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▉            | 747kB 12.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▏           | 757kB 12.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▍           | 768kB 12.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▊           | 778kB 12.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████           | 788kB 12.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▎          | 798kB 12.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▌          | 808kB 12.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▉          | 819kB 12.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████          | 829kB 12.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▎         | 839kB 12.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▋         | 849kB 12.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▉         | 860kB 12.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▏        | 870kB 12.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▍        | 880kB 12.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▊        | 890kB 12.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████        | 901kB 12.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▎       | 911kB 12.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▌       | 921kB 12.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▊       | 931kB 12.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████       | 942kB 12.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▎      | 952kB 12.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▋      | 962kB 12.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▉      | 972kB 12.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▏     | 983kB 12.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▍     | 993kB 12.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▊     | 1.0MB 12.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████     | 1.0MB 12.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▎    | 1.0MB 12.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▌    | 1.0MB 12.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▊    | 1.0MB 12.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████    | 1.1MB 12.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▎   | 1.1MB 12.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▋   | 1.1MB 12.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▉   | 1.1MB 12.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▏  | 1.1MB 12.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▍  | 1.1MB 12.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▊  | 1.1MB 12.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████  | 1.1MB 12.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▏ | 1.1MB 12.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▌ | 1.1MB 12.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▊ | 1.2MB 12.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████ | 1.2MB 12.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▎| 1.2MB 12.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▋| 1.2MB 12.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▉| 1.2MB 12.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 1.2MB 12.8MB/s \n",
      "\u001b[?25hInstalling collected packages: sentencepiece\n",
      "Successfully installed sentencepiece-0.1.95\n"
     ]
    }
   ],
   "source": [
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 114,
     "referenced_widgets": [
      "22da6a5b2dae429a9c564d522f4a79bc",
      "9eb32b75218e43398d4cf9cc813788c9",
      "b269b04f3e404212a3610b3de84dc551",
      "52d31e349bf94a55be076a420dfdbc76",
      "ab880266879c4fb4b91427f81ba8e987",
      "dcd6887760e94121a38ca44a9d956861",
      "24d54066f4da4ae58cb541709e966b0c",
      "d5d1a8101793408b9ba243f302b1b000",
      "ebbbe2d972a14ef9be1563219da7ad2e",
      "145163cbadd1442cb1b0c6e20d3f8a9f",
      "7c92dbd6927141b1922bd067a02bc54b",
      "febcc9aaa184403c9dd8bbb66242a458",
      "2b54f5b605cd44629547a058bfa7738b",
      "95f7f39cdc76466283d730fd73e9a0b1",
      "eb5fd91c4b3840a68907f6d204c8c150",
      "3dfb6a36168c4a04aece60a336922b14"
     ]
    },
    "executionInfo": {
     "elapsed": 84770,
     "status": "ok",
     "timestamp": 1619446025501,
     "user": {
      "displayName": "Ning Zhang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhRCnmT8mmairzuShAibDId7kDGmrCXjp8yIjrCOw=s64",
      "userId": "12536691088853738123"
     },
     "user_tz": -480
    },
    "id": "d4WXOe-3j4SE",
    "outputId": "dc0ff7b8-21e7-463b-d6e9-362f1b6cfae1"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22da6a5b2dae429a9c564d522f4a79bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=760289.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebbbe2d972a14ef9be1563219da7ad2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1312669.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "#from transformers.models.roberta.tokenization_roberta import RobertaTokenizer\n",
    "#import sentencepiece\n",
    "#bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "from transformers.models.albert.tokenization_albert import AlbertTokenizer\n",
    "bert_tokenizer = AlbertTokenizer.from_pretrained('albert-base-v2', do_lower_case=True)\n",
    "#model =BertModel.from_pretrained('bert-base-uncased')\n",
    "output_directory = 'outputs'\n",
    "\n",
    "# If output directory doesn't exist create one\n",
    "if not os.path.exists(output_directory):\n",
    "  os.makedirs(output_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U6rFZIJNHlU3"
   },
   "outputs": [],
   "source": [
    "#Class to store questions, their answers along with the starting index of the answer and end index of answer and tokens in the story\n",
    "class QA(object):\n",
    "  def __init__(\n",
    "            self,\n",
    "            question_answer_id,\n",
    "            question_text,\n",
    "            document_tokens,\n",
    "            original_answer_text=None,\n",
    "            answer_start_position=None,\n",
    "            answer_end_position=None,\n",
    "            additional_answers=None,\n",
    "    ):\n",
    "    self.question_answer_id = question_answer_id\n",
    "    self.question_text = question_text\n",
    "    self.document_tokens = document_tokens\n",
    "    self.original_answer_text = original_answer_text\n",
    "    self.answer_start_position = answer_start_position\n",
    "    self.answer_end_position = answer_end_position\n",
    "    self.additional_answers = additional_answers\n",
    "\n",
    "# Class to store features, input ids, input mask, segment ids, start positions, end positions, etc\n",
    "class DataFeatures(object):\n",
    "  def __init__(self,\n",
    "                 unique_id,\n",
    "                 example_index,\n",
    "                 document_span_index,\n",
    "                 tokens,\n",
    "                 token_to_origin_mapping,\n",
    "                 token_max_context,\n",
    "                 input_ids,\n",
    "                 input_mask,\n",
    "                 segments,\n",
    "                 start_position=None,\n",
    "                 end_position=None,\n",
    "                 class_index=None):            \n",
    "    self.unique_id = unique_id\n",
    "    self.example_index = example_index\n",
    "    self.document_span_index = document_span_index\n",
    "    self.tokens = tokens\n",
    "    self.token_to_origin_mapping = token_to_origin_mapping\n",
    "    self.token_max_context = token_max_context\n",
    "    self.input_ids = input_ids\n",
    "    self.input_mask = input_mask\n",
    "    self.segments = segments\n",
    "    self.start_position = start_position\n",
    "    self.end_position = end_position\n",
    "    self.class_index = class_index\n",
    "\n",
    "\n",
    "# Function to read COQA datasets and process the data\n",
    "def get_data_from_coqa(isTrain, input_file, history_len=2, add_QA_tag=False):\n",
    "\n",
    "# Check if the character is a white space\n",
    "  def check_whitespace(char):\n",
    "        if char == \" \" or char == \"\\t\" or char == \"\\r\" or char == \"\\n\" or ord(char) == 0x202F:\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "# Token conversion\n",
    "  def tokenize_string(str):\n",
    "        if (str.lower() == '-lrb-'):\n",
    "            str = '('\n",
    "        elif (str.lower() == '-rrb-'):\n",
    "            str = ')'\n",
    "        elif (str.lower() == '-lsb-'):\n",
    "            str = '['\n",
    "        elif (str.lower() == '-rsb-'):\n",
    "            str = ']'\n",
    "        elif (str.lower() == '-lcb-'):\n",
    "            str = '{'\n",
    "        elif (str.lower() == '-rcb-'):\n",
    "            str = '}'\n",
    "        return str\n",
    "\n",
    "  def space_extension(matchobject):\n",
    "    return ' ' + matchobject.group(0) + ' '  \n",
    "\n",
    " # Preprocessing \n",
    "  def pre_processing(word):\n",
    "    word = re.sub(\n",
    "        u'-|\\u2010|\\u2011|\\u2012|\\u2013|\\u2014|\\u2015|%|\\[|\\]|:|\\(|\\)|/|\\t',\n",
    "        space_extension, word)\n",
    "    word = word.strip(' \\n')\n",
    "    word = re.sub('\\s+', ' ', word)\n",
    "    return word\n",
    "\n",
    "  # Process text to return output as words with their indexes in the sentences \n",
    "  def processing(main_text):\n",
    "          processed_text = {'word': [], 'offsets': [], 'sentences': []}\n",
    " \n",
    "          for token in main_text:\n",
    "              processed_text['word'].append(tokenize_string(token.text))\n",
    "              processed_text['offsets'].append((token.idx, token.idx + len(token.text)))\n",
    "          #print(\"=======offset is\", (token.idx, token.idx + len(token.text)), \"=====word is\", tokenize_string(token.text))\n",
    "\n",
    "          word_index = 0\n",
    "          for sentence in main_text.sents:\n",
    "              processed_text['sentences'].append((word_index, word_index + len(sentence)))\n",
    "              word_index += len(sentence)\n",
    "          #print(\"=======sentence is\",  word_index, word_index + len(sentence) )\n",
    "\n",
    "          assert word_index == len(processed_text['word'])\n",
    "           \n",
    "          return processed_text\n",
    "\n",
    "  # Get the context offsets\n",
    "  def context_offsets(words, raw_text):\n",
    "    #print(words, raw_text)\n",
    "    raw_text_context_offsets = []\n",
    "    r = 0\n",
    "    for token in words:\n",
    "        while r < len(raw_text) and re.match('\\s', raw_text[r]):\n",
    "            r += 1\n",
    "        if raw_text[r:r + len(token)] != token:\n",
    "            print('Error', token, 'Raw Text:', raw_text)\n",
    "\n",
    "        raw_text_context_offsets.append((r, r + len(token)))\n",
    "        r += len(token)\n",
    " \n",
    "    return raw_text_context_offsets\n",
    "\n",
    "  # Function to find span with start and end index provided\n",
    "  def define_span_indices(offsets, start_pos, end_pos):\n",
    "     \n",
    "    span_start_index = -1\n",
    "    span_end_index = -1\n",
    "    #print(\"offset is\", offsets)\n",
    "    for i, offset in enumerate(offsets):\n",
    "        if (span_start_index < 0) or (start_pos >= offset[0]):\n",
    "            span_start_index = i\n",
    "        if (span_end_index < 0) and (end_pos <= offset[1]):\n",
    "            span_end_index = i\n",
    "    #print(\"span\",span_start_index, span_end_index)\n",
    "    return (span_start_index, span_end_index)\n",
    "\n",
    "# Removing punctuations, lowering texts and removing extra white spaces\n",
    "  def pre_process_answer(s):\n",
    "    \n",
    "    \n",
    "    # Remove articles from the text\n",
    "    def remove_articles(text):\n",
    "        reg_expression = re.compile(r'\\b(a|an|the)\\b', re.UNICODE)\n",
    "        return re.sub(reg_expression, ' ', text)\n",
    "    \n",
    "    # Remove white spaces from the text\n",
    "    def adjust_white_space(text):\n",
    "        return ' '.join(text.split())\n",
    "\n",
    "    # Remove punctuations from the text\n",
    "    def remove_punctuations(text):\n",
    "        rem = set(string.punctuation)\n",
    "        return ''.join(c for c in text if c not in rem)\n",
    "\n",
    "    # Lower the text characters\n",
    "    def lowering_text(text):\n",
    "        return text.lower()\n",
    "     \n",
    "\n",
    "    return adjust_white_space(remove_articles(remove_punctuations(lowering_text(s))))  \n",
    "\n",
    "# Find the span providing the context and offsets  \n",
    "  def span_with_ground_truth(context, offsets, ground_truth):\n",
    "\n",
    "    best_F1 = 0.0\n",
    "    best_span = (len(offsets) - 1, len(offsets) - 1)\n",
    "    ground_truth_temp = pre_process_answer(pre_processing(ground_truth)).split()\n",
    "\n",
    "    ls = [\n",
    "        i for i in range(len(offsets))\n",
    "        if context[offsets[i][0]:offsets[i][1]].lower() in ground_truth\n",
    "    ]\n",
    "\n",
    "    for i in range(len(ls)):\n",
    "        for j in range(i, len(ls)):\n",
    "            prediction = pre_process_answer(\n",
    "                pre_processing(\n",
    "                    context[offsets[ls[i]][0]:offsets[ls[j]][1]])).split()\n",
    "            common = Counter(prediction) & Counter(ground_truth_temp)\n",
    "            num_same = sum(common.values())\n",
    "\n",
    "            #print(num_same, \"common span\")\n",
    "            if num_same > 0:\n",
    "                precision = 1.0 * num_same / len(prediction)\n",
    "                recall = 1.0 * num_same / len(ground_truth_temp)\n",
    "                F1 = (2 * precision * recall) / (precision + recall)\n",
    "                if F1 > best_F1:\n",
    "                    best_F1 = F1\n",
    "                    best_span = (ls[i], ls[j])\n",
    "     \n",
    "    #print(best_span, \"best span\")\n",
    "\n",
    "    return best_span\n",
    "\n",
    "  nlp = spacy.load(\"en_core_web_sm\")\n",
    "  # Read training file\n",
    "  with open(input_file, \"r\", encoding='utf-8') as reader:\n",
    "        input_text_file = json.load(reader)[\"data\"]\n",
    "  print(len(input_text_file))\n",
    "  samples = []\n",
    "  input_text_file = input_text_file \n",
    "############################################################\n",
    "############################################################\n",
    "############################################################\n",
    "  if isTrain:\n",
    "    data_len =  len(input_text_file) # Restricted training data due to hardware limitations\n",
    "  else:\n",
    "    data_len =  len(input_text_file) # Entire Development Data is loaded \n",
    "  number_yes = 0\n",
    "  number_no = 0\n",
    "  number_unknown = 0\n",
    "  number_span = 0 \n",
    "  number_nonespan = 0 \n",
    "  # Fetch and store story, questions and answers after processing the text\n",
    "  for data_index in tqdm(range(data_len), desc='Generating examples'):\n",
    "    input_data = input_text_file[data_index]\n",
    "    context_string = input_data['story']\n",
    "    input_data_object = {\n",
    "        'context': context_string,\n",
    "        'source': input_data['source'],\n",
    "        'id': input_data['id'],\n",
    "        'filename': input_data['filename']\n",
    "    }\n",
    "     \n",
    "     \n",
    "    nlp_context = nlp(pre_processing(context_string)) \n",
    "     \n",
    "    input_data_object['annotated_context'] = processing(nlp_context)\n",
    "     \n",
    "    input_data_object['raw_context_offsets'] = context_offsets(\n",
    "          input_data_object['annotated_context']['word'], context_string)\n",
    "      \n",
    "    assert len(input_data['questions']) == len(input_data['answers'])\n",
    "    additional_answers = {} \n",
    "    if 'additional_answers' in input_data:\n",
    "      for k, answer in input_data['additional_answers'].items():\n",
    "        if len(answer) == len(input_data['answers']):\n",
    "          for example in answer:\n",
    "            index = example['turn_id']\n",
    "            if index not in additional_answers:\n",
    "              additional_answers[index] = []\n",
    "            additional_answers[index].append(example['input_text'])\n",
    "    \n",
    "    \n",
    "    for i in range(len(input_data['questions'])):\n",
    "      question, answer = input_data['questions'][i], input_data['answers'][i]\n",
    "      assert question['turn_id'] == answer['turn_id']\n",
    "       \n",
    "\n",
    "      index = question['turn_id']\n",
    "      _qas = {\n",
    "          'turn_id': index,\n",
    "          'question': question['input_text'],\n",
    "          'answer': answer['input_text']\n",
    "      }\n",
    "       \n",
    "      if index in additional_answers:\n",
    "        _qas['additional_answers'] = additional_answers[index]\n",
    "      _qas['raw_answer'] = answer['input_text']\n",
    "      \n",
    "      if _qas['raw_answer'].lower() in ['yes', 'yes.']:\n",
    "        _qas['raw_answer'] = 'yes'\n",
    "        number_yes =  number_yes+1\n",
    "      if _qas['raw_answer'].lower() in ['no', 'no.']:\n",
    "        \n",
    "        _qas['raw_answer'] = 'no'\n",
    "        number_no =number_no +1\n",
    "      if _qas['raw_answer'].lower() in ['unknown', 'unknown.']:\n",
    "        \n",
    "        _qas['raw_answer'] = 'unknown'  \n",
    "        number_unknown = number_unknown+1     \n",
    "      _qas['answer_span_start'] = answer['span_start']\n",
    "      _qas['answer_span_end'] = answer['span_end']\n",
    "       \n",
    "      start = answer['span_start']\n",
    "      end = answer['span_end']\n",
    "      chosen_text = input_data_object['context'][start:end].lower()\n",
    "      \n",
    "      while len(chosen_text) > 0 and check_whitespace(chosen_text[0]):\n",
    "        chosen_text = chosen_text[1:]\n",
    "        start += 1\n",
    "       \n",
    "      while len(chosen_text) > 0 and check_whitespace(chosen_text[-1]):\n",
    "        chosen_text = chosen_text[:-1]\n",
    "        end -= 1\n",
    "        \n",
    "      \n",
    "      input_text = _qas['answer'].strip().lower() \n",
    "      if input_text in chosen_text:\n",
    "        #print(input_text, \"=====\",chosen_text)\n",
    "        input_text = _qas['answer'].strip().lower() \n",
    "        number_span = number_span+1\n",
    "        p = chosen_text.find(input_text)\n",
    "         \n",
    "        #get the answer span from raw text when the answer can be extracted exactly\n",
    "        _qas['answer_span'] = define_span_indices(input_data_object['raw_context_offsets'],\n",
    "                                                start + p,\n",
    "                                                start + p + len(input_text))\n",
    "        #print(input_data_object['raw_context_offsets'])\n",
    "        #_qas['raw_long_question'] = question['input_text']\n",
    "###########################here remove the else to every question)\n",
    "      else:\n",
    "#########################################################################\n",
    "        input_text = answer['span_text'].strip().lower()\n",
    "        number_nonespan =number_nonespan +1 \n",
    "#########################################################################\n",
    "         \n",
    "        _qas['answer_span'] = span_with_ground_truth(\n",
    "                      input_data_object['context'], input_data_object['raw_context_offsets'],\n",
    "                      input_text)\n",
    "        #look back maximumly 2 questions \n",
    "     \n",
    "      long_question = ''\n",
    "      for j in range(i - history_len, i + 1):\n",
    "           if j < 0:\n",
    "             continue\n",
    "           long_question += (' <Q> ' if add_QA_tag else\n",
    "                                  ' ') + input_data['questions'][j]['input_text']\n",
    "           \n",
    "           if j < i:\n",
    "                    long_question += (' <A> ' if add_QA_tag else\n",
    "                                      ' ') + input_data['answers'][j]['input_text']\n",
    "           \n",
    "           long_question = long_question.strip()\n",
    "############################################################################################################################################################################           \n",
    "           #add question history \n",
    "           #print(long_question)\n",
    "           _qas['raw_long_question'] = long_question\n",
    "############################################################################################################################################################################\n",
    "           \n",
    "           _qas['annotated_long_question'] = processing(\n",
    "                nlp(pre_processing(long_question)))\n",
    "           #offset is the letter position of the word\n",
    "   # Store questions along with their answers     \n",
    "      sample = QA(\n",
    "                question_answer_id =input_data_object['id'] + ' ' + str(_qas['turn_id']),\n",
    "                question_text =_qas['raw_long_question'],\n",
    "                document_tokens =input_data_object['annotated_context']['word'],\n",
    "                original_answer_text =_qas['raw_answer'],\n",
    "                answer_start_position =_qas['answer_span'][0],\n",
    "                answer_end_position =_qas['answer_span'][1],\n",
    "                additional_answers=_qas['additional_answers'] if 'additional_answers' in _qas else None,\n",
    "                )\n",
    "      \n",
    "      samples.append(sample)\n",
    "  print(\"yes\",number_yes,\"no\", number_no, \"unknown\",number_unknown,\"span\",number_span, number_nonespan)\n",
    "      #print(sample.question_answer_id, sample.question_text, sample.original_answer_text,  sample.answer_start_position, sample.answer_end_position, sample.additional_answers )#, sample.question_text,sample.original_answer_text)\n",
    "  return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14374,
     "status": "ok",
     "timestamp": 1619446549226,
     "user": {
      "displayName": "Ning Zhang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhRCnmT8mmairzuShAibDId7kDGmrCXjp8yIjrCOw=s64",
      "userId": "12536691088853738123"
     },
     "user_tz": -480
    },
    "id": "nouT83wYIUyQ",
    "outputId": "9121135c-3976-493f-aa3d-a78784ad3835"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating examples:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating examples: 100%|██████████| 5/5 [00:11<00:00,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes 5 no 5 unknown 1 span 53 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Read CoQA training file, Needs to provide the training file path here\n",
    "training_samples = get_data_from_coqa(True, input_file=\"data/coqa-train-v1.0.json\", history_len= 2, add_QA_tag= False)\n",
    "#print(training_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DImDVoDhIkK_"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Function to improve the answer by modifying the start and end indexes to appropriate answer\n",
    "def modify_answer_span(document_tokens, input_start_index, input_end_index, tokenizer, original_answer_text):\n",
    "  #print(document_tokens, input_start_index, input_end_index, tokenizer, original_answer_text)\n",
    "  token_answer_text = \" \".join(bert_tokenizer.tokenize(original_answer_text))\n",
    "  \n",
    "  # loop to modify the indexes for appropriate answer\n",
    "  for new_start_index in range(input_start_index, input_end_index + 1):\n",
    "    for new_end_index in range(input_end_index, new_start_index - 1, -1):\n",
    "      text_span = \" \".join(document_tokens[new_start_index:(new_end_index + 1)])\n",
    "      if text_span == token_answer_text:\n",
    "        return (new_start_index, new_end_index)\n",
    "  \n",
    " \n",
    "  return (input_start_index, input_end_index)\n",
    "\n",
    "# Function to select the span with the maximum context for the token\n",
    "def check_max_context(document_spans, current_span_index, current_position):\n",
    "   \n",
    "  best_score = None\n",
    "  best_span_index = None\n",
    "  for (span_index, document_span) in enumerate(document_spans):\n",
    "    end = document_span.start + document_span.length - 1\n",
    "    if current_position < document_span.start:\n",
    "            continue\n",
    "    if current_position > end:\n",
    "            continue\n",
    "    left_context = current_position - document_span.start\n",
    "    right_context = end - current_position\n",
    "    score = min(left_context, right_context) + 0.01 * document_span.length # Score calculation for the current start and end index\n",
    "    if best_score is None or score > best_score:  # selection of indexes based on better score\n",
    "      best_score = score\n",
    "      best_span_index = span_index\n",
    "  \n",
    "  return current_span_index == best_span_index\n",
    "# Function to convert CoQA Data to features\n",
    "def converting_examples_into_features(examples, tokenizer, maximum_sequence_length, document_stride, maximum_query_length):\n",
    "   \n",
    "  unique_id = 1000000000\n",
    "  features = []\n",
    "  for (example_index, example) in enumerate(tqdm(examples, desc=\"Generating features for CoQA...\")):\n",
    "    query_token = tokenizer.tokenize(example.question_text)\n",
    "     \n",
    "    class_index = 3\n",
    "\n",
    "    # Check for the type of answer whether it is yes/no type otherwise set to unknown\n",
    "    if example.original_answer_text == 'yes':\n",
    "      class_index = 0  \n",
    "    elif example.original_answer_text == 'no':\n",
    "      class_index = 1 \n",
    "    elif example.original_answer_text == 'unknown':\n",
    "      class_index = 2  \n",
    "  \n",
    "    # Check for the length of the query and select the query until uth maximum query length set\n",
    "    if len(query_token) > maximum_query_length:\n",
    "      query_token = query_token[0:maximum_query_length]\n",
    "    \n",
    "    token_to_original_index = []\n",
    "    original_to_token_index = []\n",
    "    all_document_tokens = []\n",
    "\n",
    "    for (i, token) in enumerate(example.document_tokens):\n",
    "      original_to_token_index.append(len(all_document_tokens))\n",
    "      sub_tokens = tokenizer.tokenize(token)\n",
    "      for sub_token in sub_tokens:\n",
    "        token_to_original_index.append(i)\n",
    "        all_document_tokens.append(sub_token)\n",
    "     \n",
    "    token_start_position = None\n",
    "    token_end_position = None\n",
    "    if class_index < 3:\n",
    "      token_start_position, token_end_position = 0,0\n",
    "    else:\n",
    "      token_start_position = original_to_token_index[example.answer_start_position]\n",
    "      if example.answer_end_position < len(example.document_tokens) - 1:\n",
    "        token_end_position = original_to_token_index[example.answer_end_position + 1] - 1\n",
    "      else:\n",
    "        token_end_position = len(all_document_tokens) - 1\n",
    "      (token_start_position, token_end_position) = modify_answer_span(\n",
    "                all_document_tokens, token_start_position, token_end_position, tokenizer,\n",
    "                example.original_answer_text)\n",
    "    \n",
    "     \n",
    "    maximum_tokens_for_document = maximum_sequence_length - len(query_token) - 3\n",
    "     \n",
    "    _DocSpan = collections.namedtuple(  \n",
    "            \"DocSpan\", [\"start\", \"length\"])\n",
    " ######################################################################need to figure out this##################################    \n",
    "    document_spans = []\n",
    "    start_offset = 0\n",
    "    while start_offset < len(all_document_tokens):\n",
    "      length = len(all_document_tokens) - start_offset\n",
    "      if length > maximum_tokens_for_document:\n",
    "        length = maximum_tokens_for_document\n",
    "      document_spans.append(_DocSpan(start=start_offset, length=length))\n",
    "      if start_offset + length == len(all_document_tokens):\n",
    "        break\n",
    "      start_offset += min(length, document_stride)\n",
    "      \n",
    "    \n",
    "    # loop to add the seperator tokens in the input sequence\n",
    "    for (document_span_index, document_span) in enumerate(document_spans):   \n",
    "      slice_class_index = class_index\n",
    "      tokens = []\n",
    "      token_to_origin_mapping = {}\n",
    "      token_max_context = {}\n",
    "      segment_ids = []\n",
    "      tokens.append(\"[CLS]\")\n",
    "      segment_ids.append(0)\n",
    "      \n",
    "      for token in query_token:\n",
    "          \n",
    "          tokens.append(token)\n",
    "          segment_ids.append(0)\n",
    "      #this is for single query examples\n",
    "      tokens.append(\"[SEP]\")\n",
    "\n",
    "      segment_ids.append(0)\n",
    "       \n",
    "      for i in range(document_span.length):\n",
    "        split_token_index = document_span.start + i\n",
    "        token_to_origin_mapping[len(\n",
    "                    tokens)] = token_to_original_index[split_token_index]\n",
    "        is_max_context = check_max_context(document_spans,\n",
    "                                                       document_span_index,\n",
    "                                                       split_token_index)\n",
    "        token_max_context[len(tokens)] = is_max_context\n",
    "        tokens.append(all_document_tokens[split_token_index])\n",
    "        segment_ids.append(1)\n",
    "      #this merges the entire paragraph\n",
    "      tokens.append(\"[SEP]\")\n",
    "      segment_ids.append(1)\n",
    "       \n",
    "      input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "      \n",
    "      input_mask = [1] * len(input_ids)\n",
    "       \n",
    "\n",
    "      while len(input_ids) < maximum_sequence_length:\n",
    "        input_ids.append(0)\n",
    "        input_mask.append(0)\n",
    "        segment_ids.append(0)\n",
    "      #print(input_ids, input_mask,segment_ids )\n",
    "      assert len(input_ids) == maximum_sequence_length\n",
    "      assert len(input_mask) == maximum_sequence_length\n",
    "      assert len(segment_ids) == maximum_sequence_length\n",
    "\n",
    "      # Start and end position calculations\n",
    "      start_position = None\n",
    "      end_position = None\n",
    "      if class_index >= 3:\n",
    "        document_start = document_span.start\n",
    "        document_end = document_span.start + document_span.length - 1\n",
    "         \n",
    "        out_of_span = False\n",
    "  \n",
    "      \n",
    "        if not (token_start_position >= document_start\n",
    "                        and token_end_position <= document_end):\n",
    "           \n",
    "          out_of_span = True\n",
    "        if out_of_span:\n",
    "          start_position = 0\n",
    "          end_position = 0\n",
    "          slice_class_index = 2\n",
    "        else: #why use document offest\n",
    "          document_offset = len(query_token) + 2\n",
    "          start_position = token_start_position - document_start + document_offset\n",
    "          end_position = token_end_position - document_start + document_offset\n",
    "          \n",
    "      else:\n",
    "        start_position = 0\n",
    "        end_position = 0\n",
    "      \n",
    "      # add the current feature calculated to the features list   \n",
    "      features.append(                            \n",
    "          DataFeatures(unique_id=unique_id, #record id\n",
    "                        example_index=example_index, #question id\n",
    "                        document_span_index=document_span_index,#document id\n",
    "                        tokens=tokens,#tokens for the entire questions and context texts\n",
    "                        token_to_origin_mapping=token_to_origin_mapping, #mapping the sequence with original index\n",
    "                        token_max_context=token_max_context,#whether exceed the maximum length\n",
    "                        input_ids=input_ids,#the tokenizer word embedding\n",
    "                        input_mask=input_mask,#the mask for all tokens, with word is 1, the rest padded with 0, 450\n",
    "                        segments=segment_ids,#segments of historical question and answer 0, context 1 \n",
    "                        start_position=start_position,#start position of the answer span\n",
    "                        end_position=end_position,#end position of the answer span\n",
    "                        class_index=slice_class_index)) #whether yes, no, unknow, or usual\n",
    "     \n",
    "      unique_id += 1\n",
    "       \n",
    "  return features  # Return all the features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3295,
     "status": "ok",
     "timestamp": 1619446552533,
     "user": {
      "displayName": "Ning Zhang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhRCnmT8mmairzuShAibDId7kDGmrCXjp8yIjrCOw=s64",
      "userId": "12536691088853738123"
     },
     "user_tz": -480
    },
    "id": "lYCklFhiIrpv",
    "outputId": "24532cf1-1c8e-4d01-da11-06e918c6b09e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating features for CoQA...: 100%|██████████| 75/75 [00:01<00:00, 52.73it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "training_data_features = converting_examples_into_features(\n",
    "                examples=training_samples,\n",
    "                tokenizer=bert_tokenizer,\n",
    "                maximum_sequence_length=450,\n",
    "                document_stride=128,\n",
    "                maximum_query_length=75,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3291,
     "status": "ok",
     "timestamp": 1619446552534,
     "user": {
      "displayName": "Ning Zhang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhRCnmT8mmairzuShAibDId7kDGmrCXjp8yIjrCOw=s64",
      "userId": "12536691088853738123"
     },
     "user_tz": -480
    },
    "id": "yKSK94-iItqo",
    "outputId": "127d555f-424e-4e21-f859-1daa6d8d7a5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   2,   76,   23,  ...,    0,    0,    0],\n",
      "        [   2,   76,   23,  ...,    0,    0,    0],\n",
      "        [   2,   76,   23,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [   2,   17,   72,  ...,    0,    0,    0],\n",
      "        [   2,   23,   39,  ..., 3571,   13,    3],\n",
      "        [   2,   23,   39,  ...,    0,    0,    0]])\n",
      "tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]])\n",
      "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]])\n",
      "tensor([ 48, 136, 137, 141, 196, 254, 262,  25,  57, 121, 247, 271, 176,   0,\n",
      "        183, 177,  62, 331, 214, 229,  77,  75, 114, 361, 378, 238,  50,   0,\n",
      "          0,  90,   0,   0, 148,   0, 175,  47, 165,  37, 188,   0,   0, 236,\n",
      "        108, 309, 181, 295, 167, 326, 198, 318, 190,   0,   0, 351, 372, 244,\n",
      "          0,   0,   0,   0, 140, 173, 171,  43, 246, 118,   0,   0, 220,  92,\n",
      "        107,   0,  69,   0, 120,   0,   0,   0, 299, 171, 272, 348, 337, 209,\n",
      "        267, 139, 279, 402, 274, 397, 269, 403, 275, 414,  69,   0, 188,  60,\n",
      "        143,   0, 172,  44,   0,   0, 111,   0, 122,   0,   0,   0, 325, 197,\n",
      "        313, 185])\n",
      "tensor([ 52, 136, 147, 146, 217, 264, 262,  28,  59, 124, 256, 271, 186,   0,\n",
      "        185, 188,  64, 334, 233, 236,  79,  79, 116, 362, 378, 241,  50,   0,\n",
      "          0, 104,   0,   0, 153,   0, 177,  49, 177,  49, 193,   0,   0, 249,\n",
      "        121, 311, 183, 297, 169, 327, 199, 321, 193,   0,   0, 356, 385, 257,\n",
      "          0,   0,   0,   0, 141, 183, 185,  57, 249, 121,   0,   0, 225,  97,\n",
      "        111,   0,  73,   0, 125,   0,   0,   0, 314, 186, 275, 351, 338, 210,\n",
      "        268, 140, 284, 410, 282, 400, 272, 403, 275, 419,  76,   0, 228, 100,\n",
      "        144,   0, 173,  45,   0,   0, 112,   0, 125,   0,   0,   0, 338, 210,\n",
      "        315, 187])\n",
      "<torch.utils.data.dataset.TensorDataset object at 0x7ff04cbb1e10>\n",
      "<torch.utils.data.sampler.RandomSampler object at 0x7ff04b7166d0>\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7ff04cbb17d0>\n"
     ]
    }
   ],
   "source": [
    "# Tensor construction for input ids\n",
    "dataset_input_ids = torch.tensor([f.input_ids for f in training_data_features], dtype=torch.long)\n",
    "print(dataset_input_ids)\n",
    "\n",
    "# Tensor construction for input masks\n",
    "dataset_input_masks = torch.tensor([f.input_mask for f in training_data_features], dtype=torch.long)\n",
    "print(dataset_input_masks)\n",
    "\n",
    "# Tensor construction for segment ids\n",
    "dataset_segment_ids = torch.tensor([f.segments for f in training_data_features], dtype=torch.long)\n",
    "print(dataset_segment_ids)\n",
    "\n",
    "#Tensor construction for start positions\n",
    "dataset_start_positions = torch.tensor([f.start_position for f in training_data_features], dtype=torch.long)\n",
    "print(dataset_start_positions)\n",
    "\n",
    "#Tensor construction for end positions\n",
    "dataset_end_positions = torch.tensor([f.end_position for f in training_data_features], dtype=torch.long)\n",
    "print(dataset_end_positions)\n",
    "\n",
    "dataset_class_index = torch.tensor([f.class_index for f in training_data_features], dtype=torch.long)\n",
    "\n",
    "\n",
    "# Wrapping tensors in a tensor dataset\n",
    "training_data = TensorDataset(dataset_input_ids, dataset_input_masks, dataset_segment_ids, dataset_start_positions, dataset_end_positions,dataset_class_index)\n",
    "torch.save(training_data, 'outputs/train_tensor_albert_base_16.pt')\n",
    "training_data_save = torch.load('outputs/train_tensor_albert_base_16.pt')\n",
    "print(training_data_save)\n",
    "\n",
    "# Train sampler to return random indices\n",
    "training_data_sampler = RandomSampler(training_data_save)\n",
    "#training_data_sampler = SequentialSampler(training_data_save)\n",
    "print(training_data_sampler)\n",
    "\n",
    "# Creating python iterable over tensor datasets\n",
    "training_dataloader = DataLoader(training_data_save, sampler=training_data_sampler, batch_size=8) # has to be little else the server will have runtime out error\n",
    "print(training_dataloader)\n",
    "from math import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 8541,
     "status": "ok",
     "timestamp": 1619446684235,
     "user": {
      "displayName": "Ning Zhang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhRCnmT8mmairzuShAibDId7kDGmrCXjp8yIjrCOw=s64",
      "userId": "12536691088853738123"
     },
     "user_tz": -480
    },
    "id": "ubsX67_VOXWN",
    "outputId": "737bfc8e-1857-4af5-eaa3-a12482b98d5b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at albert-base-v2 were not used when initializing CoQAwithAlbert: ['predictions.bias', 'predictions.LayerNorm.weight', 'predictions.LayerNorm.bias', 'predictions.dense.weight', 'predictions.dense.bias', 'predictions.decoder.weight', 'predictions.decoder.bias']\n",
      "- This IS expected if you are initializing CoQAwithAlbert from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CoQAwithAlbert from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of CoQAwithAlbert were not initialized from the model checkpoint at albert-base-v2 and are newly initialized: ['linear.weight', 'linear.bias', 'qa_outputs.weight', 'qa_outputs.bias', 'class_outputs.weight', 'class_outputs.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Iteration:   0%|          | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 1/15 [00:00<00:03,  3.96it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.565906524658203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  13%|█▎        | 2/15 [00:00<00:03,  4.01it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.532534599304199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  20%|██        | 3/15 [00:00<00:02,  4.05it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.558341026306152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  27%|██▋       | 4/15 [00:00<00:02,  4.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.570143699645996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  33%|███▎      | 5/15 [00:01<00:02,  4.09it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.524482250213623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  40%|████      | 6/15 [00:01<00:02,  4.10it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.536935806274414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  47%|████▋     | 7/15 [00:01<00:01,  4.11it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.542910099029541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  53%|█████▎    | 8/15 [00:01<00:01,  4.12it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.552838325500488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  60%|██████    | 9/15 [00:02<00:01,  4.12it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.568912029266357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  67%|██████▋   | 10/15 [00:02<00:01,  4.12it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.568861484527588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  73%|███████▎  | 11/15 [00:02<00:00,  4.12it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.551202774047852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  80%|████████  | 12/15 [00:02<00:00,  4.12it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.559648513793945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  87%|████████▋ | 13/15 [00:03<00:00,  4.11it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.546690940856934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration: 100%|██████████| 15/15 [00:03<00:00,  4.30it/s]\n",
      "Epoch: 100%|██████████| 1/1 [00:03<00:00,  3.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.507542610168457\n",
      "7.5691375732421875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from transformers import AlbertModel,AlbertConfig    \n",
    "from transformers import AlbertModel, AdamW, AlbertConfig\n",
    "AlbertPreTrainedModel = transformers.AlbertPreTrainedModel \n",
    "# Model creation using Bert Pretrained Model as a base\n",
    "class CoQAwithAlbert(AlbertPreTrainedModel):\n",
    "\n",
    "  # Configurations passed to BERT model\n",
    "  def __init__(\n",
    "            self,\n",
    "            config,\n",
    "            output_attentions=False,\n",
    "            keep_multihead_output=False,\n",
    "            class_alpha=1.0,\n",
    "            mask_p=0.0,\n",
    "    ):\n",
    "    super(CoQAwithAlbert, self).__init__(config)\n",
    "    self.class_alpha = class_alpha\n",
    "    self.mask_p = mask_p\n",
    "    self.albert = AlbertModel(\n",
    "    config,\n",
    "    )\n",
    "    self.linear = nn.Linear(config.hidden_size,config.hidden_size)\n",
    "    self.relu  = nn.ReLU()\n",
    "  \n",
    "    self.qa_outputs = nn.Linear(config.hidden_size, 2)\n",
    "    self.output_attentions = False\n",
    "    self.class_outputs = nn.Linear(config.hidden_size, 4)\n",
    "    model_config = AlbertConfig.from_pretrained('albert-base-v2', output_hidden_states=True)\n",
    "    self.albert = AlbertModel.from_pretrained('albert-base-v2', config=model_config)\n",
    "    #self.apply(self.init_bert_weights)\n",
    "    #self.apply(self.init_bert_weights)\n",
    "  \n",
    "  # Forward pass for the BERT model\n",
    "  def forward(\n",
    "            self,\n",
    "            input_ids,  # Input seq indices \n",
    "            token_type_ids=None,\n",
    "            attention_mask=None, # Masking to avoid attention\n",
    "            start_positions=None, # Starting position of the span\n",
    "            end_positions=None,  # End position of the span\n",
    "            class_index = None,\n",
    "    ):\n",
    "    outputs = self.albert(\n",
    "            input_ids,\n",
    "            token_type_ids=token_type_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            #head_mask=head_mask,\n",
    "        )\n",
    "     \n",
    "    # outputs consists of the elements based on the configurations provided to BERT\n",
    "    sequence_output= outputs[0]\n",
    "    class_outputs = outputs[1] \n",
    "    \n",
    "    span_logits_0 = self.linear(sequence_output)\n",
    "    span_logits_0 =self.relu(span_logits_0)  \n",
    "    span_logits_0 = self.linear(span_logits_0)\n",
    "    span_logits_0 =self.relu(span_logits_0)  \n",
    "    span_logits = self.qa_outputs(span_logits_0)\n",
    "    \n",
    "    class_logits_0 = self.linear(class_outputs)\n",
    "    class_logits_0 =self.relu(class_logits_0 )  \n",
    "    class_logits_0 = self.linear(class_logits_0 )\n",
    "    class_logits_0 =self.relu(class_logits_0 )  \n",
    "\n",
    "    class_logits = self.class_outputs(class_logits_0)\n",
    "    #print(span_logits_0.shape, class_logits_0.shape)\n",
    "    start_logits, end_logits = span_logits.split(1, dim=-1)\n",
    "    start_logits = start_logits.squeeze(-1)\n",
    "    end_logits = end_logits.squeeze(-1)\n",
    "    #print(class_logits.shape)\n",
    "\n",
    "    # Span extraction based on start positions and end positions\n",
    "    if start_positions is not None and end_positions is not None:\n",
    "      if len(start_positions.size()) > 1:\n",
    "        start_positions = start_positions.squeeze(-1)\n",
    "      if len(end_positions.size()) > 1:\n",
    "        end_positions = end_positions.squeeze(-1)\n",
    "      ignored_index = start_logits.size(1)\n",
    "       \n",
    "      start_positions.clamp_(0, ignored_index)\n",
    "      end_positions.clamp_(0, ignored_index)\n",
    "      #print(start_logits.shape, start_positions)\n",
    "      #print(end_logits, end_positions)\n",
    "      span_loss_factor = CrossEntropyLoss(ignore_index=ignored_index)\n",
    "      class_loss_factor = CrossEntropyLoss()\n",
    "      #here need to have the argmax for start_logits\n",
    "      #this loss is still based on the text span, there is no text generation component, need to see more how others do this piece, the model is not quite right\n",
    "      #data preprocessing done, but there is no ground truth answer therefore can't train, refer to other models, or otherwise this is still using squad method to do coqa\n",
    "      start_loss = span_loss_factor(start_logits, start_positions)\n",
    "      end_loss = span_loss_factor(end_logits, end_positions)\n",
    "      class_loss = class_loss_factor(class_logits, class_index)\n",
    "      #print(class_logits, class_index)\n",
    "      #########################################################\n",
    "      #########################################################\n",
    "      #index = class_logits.data.cpu().numpy().argmax()\n",
    "     #index_tensor = torch.argmax(class_logits)\n",
    "      loss=0\n",
    "      #add_loss =nn.L1Loss()\n",
    "     # for i, index in enumerate(class_index):\n",
    "     #   if index == torch.tensor(1).to(device):\n",
    "          #print(class_logits[i].argmax(),index, \"###############\")\n",
    "          #loss =  add_loss(class_logits[i].argmax()/index + 0.001,torch.tensor(1.0).to(device)+0.001).detach()\n",
    "     #     loss = abs((class_logits[i].argmax()/index + 0.001)-(torch.tensor(1.0).to(device)+0.001))\n",
    "          \n",
    "     #   else:\n",
    "     #     loss = 0\n",
    "       \n",
    "   \n",
    "       \n",
    "      ########################################################################################################\n",
    "      total_loss = (start_loss + end_loss) / 2 + self.class_alpha * class_loss + 0.05* loss \n",
    "      \n",
    "      return total_loss\n",
    "    return start_logits, end_logits, class_logits\n",
    "model1 = CoQAwithAlbert.from_pretrained('albert-base-v2', output_hidden_states=True)\n",
    " # Set model in training mode\n",
    "device=\"cuda\"\n",
    "model1.to(device)\n",
    "model1.train()\n",
    "\n",
    "#for albert\n",
    "RawResult = collections.namedtuple(\"RawResult\",\n",
    "                                   [\"unique_id\", \"start_logits\", \"end_logits\", \"cls_logits\"])\n",
    "\n",
    "# Calculation for optimization steps accordingly training length, which will be used for learning rate for BERT model\n",
    "train_optimization_steps = len(\n",
    "            training_dataloader\n",
    "        )\n",
    "\n",
    "# Fetch the training hyperparameters\n",
    "parameter_optimizer = list(model1.named_parameters())\n",
    "parameter_optimizer = [n for n in parameter_optimizer if 'pooler' not in n[0]]\n",
    "no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in parameter_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "    {'params': [p for n, p in parameter_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}]\n",
    "\n",
    "\n",
    "# Load apex optimizers\n",
    "optimizer = AdamW(optimizer_grouped_parameters,\n",
    "                                  lr=3e-5)\n",
    "#optimizer = FP16_Optimizer(optimizer, dynamic_loss_scale=True)\n",
    "\n",
    "\n",
    "n_gpu = torch.cuda.device_count()\n",
    "# Accuracy and loss for plotting\n",
    "plot_data = []\n",
    "for epoch in trange(1, desc=\"Epoch\"): # Epoch provided: 3, restricted for now to avoid the memory issue but can be increased to improve the model\n",
    "  for step, batch in enumerate(\n",
    "          tqdm(training_dataloader,\n",
    "                desc=\"Iteration\",\n",
    "                disable=-1 not in [-1, 0])):\n",
    "    if n_gpu == 1: # check for gpu count \n",
    "          batch = tuple(\n",
    "              t.to(device)\n",
    "              for t in batch)\n",
    "    # Get the batch data to be provided to the model\n",
    "    dataset_input_ids,dataset_input_masks,dataset_segment_ids, dataset_start_positions, dataset_end_positions, dataset_class_index = batch\n",
    "    loss = model1(dataset_input_ids, dataset_segment_ids, dataset_input_masks,\n",
    "                    dataset_start_positions, dataset_end_positions, dataset_class_index)\n",
    "     # Adding the loss to plot data to plot the graph in the end \n",
    "    loss.backward()\n",
    "    plot_data.append(loss.detach().item())\n",
    "    print(loss.detach().item())\n",
    "    if step < 5000:\n",
    "          lr_this_step = np.linspace(0, 3e-5, 5001)[1:]\n",
    "          for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = lr_this_step[step]\n",
    "    else:\n",
    "          param_group['lr']= (1+ cos(step*pi/len(training_dataloader)))*1/2*(3e-5)\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    #global_step += 1\n",
    "torch.save(model1, 'outputs/albert_base_8_2linear.pth')\n",
    "import matplotlib.pyplot as pplot\n",
    "\n",
    "# Graph plotting code X axis is Batch and Y axis is loss\n",
    "pplot.figure(figsize= (15, 10))\n",
    "pplot.title(\"Training Loss\")\n",
    "pplot.xlabel(\"Batch\")\n",
    "pplot.ylabel(\"Loss\")\n",
    "pplot.plot(plot_data)\n",
    "pplot.savefig('outputs/albert_base_8_2linear.png', dpi=300, bbox_inches='tight')\n",
    "pplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3461,
     "status": "ok",
     "timestamp": 1619446691225,
     "user": {
      "displayName": "Ning Zhang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhRCnmT8mmairzuShAibDId7kDGmrCXjp8yIjrCOw=s64",
      "userId": "12536691088853738123"
     },
     "user_tz": -480
    },
    "id": "sFKOempeI64w",
    "outputId": "4400228c-eebe-4b7d-cab0-3f2ed1d73750"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating examples:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating examples: 100%|██████████| 1/1 [00:01<00:00,  1.69s/it]\n",
      "Generating features for CoQA...:  50%|█████     | 6/12 [00:00<00:00, 53.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes 0 no 3 unknown 0 span 4 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating features for CoQA...: 100%|██████████| 12/12 [00:00<00:00, 53.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.DataFeatures object at 0x7ff04a0fb850>\n",
      "tensor([[   2,   98, 1665,  ...,    0,    0,    0],\n",
      "        [   2,   98, 1665,  ...,    0,    0,    0],\n",
      "        [   2,   98, 1665,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [   2,   98,  144,  ...,    7,   13,    3],\n",
      "        [   2,   98,  144,  ...,    0,    0,    0],\n",
      "        [   2,  113,  144,  ...,    0,    0,    0]])\n",
      "tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]])\n",
      "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]])\n",
      "<torch.utils.data.dataset.TensorDataset object at 0x7ff04c3e3990>\n",
      "<torch.utils.data.sampler.SequentialSampler object at 0x7ff04a0fb1d0>\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7ff04c3e3350>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Read COQA Dev file, File path needs to be provided where COQA dev file is stored\n",
    "testing_samples = get_data_from_coqa(False, input_file=\"data/coqa-dev-v1.0.json\",\n",
    "                                                history_len= 2,\n",
    "                                                add_QA_tag= False)\n",
    "# Converting the development examples to features\n",
    "testing_features = converting_examples_into_features(\n",
    "                examples=testing_samples,\n",
    "                tokenizer=bert_tokenizer,\n",
    "                maximum_sequence_length=450,\n",
    "                document_stride=128,\n",
    "                maximum_query_length=75,\n",
    "            )\n",
    "print(testing_features[0])\n",
    "#Tensor construction for input ids\n",
    "dataset_input_ids = torch.tensor([f.input_ids for f in testing_features], dtype=torch.long)\n",
    "print(dataset_input_ids)\n",
    "\n",
    "#Tensor construction for input masks\n",
    "dataset_input_masks = torch.tensor([f.input_mask for f in testing_features], dtype=torch.long)\n",
    "print(dataset_input_masks)\n",
    "\n",
    "#Tensor construction for segment ids\n",
    "dataset_segment_ids = torch.tensor([f.segments for f in testing_features], dtype=torch.long)\n",
    "print(dataset_segment_ids)\n",
    "\n",
    "dataset_example_index  = torch.arange(dataset_input_ids.size(0), dtype=torch.long)\n",
    "\n",
    "# Wrapping tensors in a tensor dataset\n",
    "testing_data = TensorDataset(dataset_input_ids, dataset_input_masks, dataset_segment_ids, dataset_example_index)\n",
    " \n",
    "torch.save(testing_data, 'outputs/test_tensor_albert_base_16.pt')\n",
    "testing_data_save = torch.load('outputs/test_tensor_albert_base_16.pt')\n",
    "print(testing_data_save)\n",
    "# Sampling the elements in the same order they are(sequentially)\n",
    "testing_data_sampler = SequentialSampler(testing_data_save)\n",
    "print(testing_data_sampler)\n",
    "\n",
    "# Creating python iterable over tensor dataset\n",
    "testing_dataloader = DataLoader(testing_data_save, sampler=testing_data_sampler, batch_size=8)\n",
    "print(testing_dataloader) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3821,
     "status": "ok",
     "timestamp": 1619446691992,
     "user": {
      "displayName": "Ning Zhang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhRCnmT8mmairzuShAibDId7kDGmrCXjp8yIjrCOw=s64",
      "userId": "12536691088853738123"
     },
     "user_tz": -480
    },
    "id": "w_cHAj-88Mue",
    "outputId": "85f1779f-c86b-4e7e-8f9a-5b6d84c03f4b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: 100%|██████████| 2/2 [00:00<00:00, 12.51it/s]\n"
     ]
    }
   ],
   "source": [
    " \n",
    "# Fetch the results for predictions using the trained model\n",
    "results_for_predictions = []\n",
    "for tqdm_input_ids, tqdm_input_mask, tqdm_segment_ids, tqdm_example_indices in tqdm(\n",
    "                testing_dataloader,\n",
    "                desc=\"Evaluation\",\n",
    "                disable=-1 not in [-1, 0]):\n",
    "   \n",
    "  tqdm_input_ids = tqdm_input_ids.to(device)\n",
    "  tqdm_input_mask = tqdm_input_mask.to(device)\n",
    "  tqdm_segment_ids = tqdm_segment_ids.to(device)\n",
    "\n",
    "  # Get all the results from the model\n",
    "  # Ensemble the results from Albert and BERT\n",
    "  with torch.no_grad():\n",
    "    model_batch_start_logits, model_batch_end_logits, model_batch_cls_logits = model1(tqdm_input_ids, tqdm_segment_ids, tqdm_input_mask)  \n",
    "    #model_batch_start_logits, model_batch_end_logits, model_batch_cls_logits = bert_i(tqdm_input_ids, tqdm_segment_ids, tqdm_input_mask)  \n",
    "    #model_batch_start_logits, model_batch_end_logits, model_batch_cls_logits = albert(tqdm_input_ids, tqdm_segment_ids, tqdm_input_mask)  \n",
    "    #model_batch_start_logits, model_batch_end_logits, model_batch_cls_logits = roberta(tqdm_input_ids, tqdm_segment_ids, tqdm_input_mask)    \n",
    "   # robertamodel_batch_start_logits, robertamodel_batch_end_logits, robertamodel_batch_cls_logits = roberta(tqdm_input_ids, tqdm_segment_ids, tqdm_input_mask)\n",
    "   # bertmodel_batch_start_logits, bertmodel_batch_end_logits, bertmodel_batch_cls_logits = bert(tqdm_input_ids, tqdm_segment_ids, tqdm_input_mask)\n",
    "   # albertmodel_batch_start_logits, albertmodel_batch_end_logits, albertmodel_batch_cls_logits = albert(tqdm_input_ids, tqdm_segment_ids, tqdm_input_mask)\n",
    "  #model_batch_start_logits = (bertmodel_batch_start_logits +albertmodel_batch_start_logits)/2\n",
    "  #model_batch_end_logits = (bertmodel_batch_end_logits+albertmodel_batch_end_logits)/2 \n",
    "  #model_batch_cls_logits =(bertmodel_batch_cls_logits+ albertmodel_batch_cls_logits)/2\n",
    " \n",
    "   \n",
    "  # Get the start end logists from the model and store it in results\n",
    "  for i, tqdm_example_index in enumerate(tqdm_example_indices):\n",
    "    this_start_logits = model_batch_start_logits[i].detach().cpu().tolist()\n",
    "    this_end_logits = model_batch_end_logits[i].detach().cpu().tolist()\n",
    "    this_cls_logits = model_batch_cls_logits[i].detach().cpu().tolist()\n",
    "    testing_feature = testing_features[tqdm_example_index.item()]\n",
    "    unique_id = int(testing_feature.unique_id)\n",
    " \n",
    "    # Store the prediction in the results list\n",
    "    results_for_predictions.append(\n",
    "                    RawResult(unique_id=unique_id,\n",
    "                    start_logits= this_start_logits,\n",
    "                    end_logits= this_end_logits,\n",
    "                    cls_logits= this_cls_logits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a5-x49P1AHnb"
   },
   "outputs": [],
   "source": [
    "\n",
    "op_pred_file = os.path.join(output_directory, \"Output_Preds_albert_base_8_2linear.json\")\n",
    "output_nbest_file = os.path.join(output_directory, \"nbest_predictions_albert_base_2linear.json\") \n",
    "# Get the appropriate index for the answer text\n",
    "def compute_best_indices(logits, n):\n",
    "  index_with_score = sorted(enumerate(logits),\n",
    "                             key=lambda x: x[1],\n",
    "                             reverse=True)\n",
    "   \n",
    "  best_indices = []\n",
    "  for i in range(len(index_with_score)):\n",
    "    if i >= n:\n",
    "      break\n",
    "    best_indices.append(index_with_score[i][0])\n",
    "  return best_indices\n",
    "# Get the final text fetching it from the span using the predicted answer\n",
    "def output_final_answer_text(predicted_text, original_text, low_case, v_log=False):\n",
    "  def remove_spaces(text):\n",
    "    non_space_chars = []\n",
    "    non_space_char_to_space_char_map = collections.OrderedDict()\n",
    "    for (i, c) in enumerate(text):\n",
    "      if c == \" \":\n",
    "        continue\n",
    "      non_space_char_to_space_char_map[len(non_space_chars)] = i\n",
    "      non_space_chars.append(c)\n",
    "    non_space_text = \"\".join(non_space_chars)\n",
    "    return (non_space_text, non_space_char_to_space_char_map)\n",
    "\n",
    "  # Get the BERT tokenizer to tokenize the text\n",
    "  tokenizer = BasicTokenizer(do_lower_case=low_case)\n",
    "  tokenized_text = \" \".join(tokenizer.tokenize(original_text))\n",
    "\n",
    "  # Find predicted text in the tokenized text to get the start and end positions\n",
    "  start_position = tokenized_text.find(predicted_text)\n",
    "  if start_position == -1:\n",
    "      return original_text\n",
    "  end_position = start_position + len(predicted_text) - 1\n",
    "\n",
    "  # Remove spaces if any\n",
    "  (original_non_space_text, original_non_space_to_space_map) = remove_spaces(original_text)\n",
    "  (tokenized_non_space_text, tokenized_non_space_to_space_map) = remove_spaces(tokenized_text)\n",
    "\n",
    "  if len(original_non_space_text) != len(tokenized_non_space_text):\n",
    "    return original_text\n",
    "\n",
    "  tokenized_non_space_to_space_map = {}\n",
    "  for (i, _tokenized_index) in tokenized_non_space_to_space_map.items():\n",
    "    tokenized_non_space_to_space_map[_tokenized_index] = i\n",
    "\n",
    "  # Get the start position\n",
    "  original_start_position = None\n",
    "  if start_position in tokenized_non_space_to_space_map:\n",
    "    non_space_start_position = tokenized_non_space_to_space_map[start_position]\n",
    "    if non_space_start_position in original_non_space_to_space_map:\n",
    "      original_start_position = original_non_space_to_space_map[non_space_start_position]\n",
    "  \n",
    "  # Check if the start position is None\n",
    "  if original_start_position is None:\n",
    "    return original_text\n",
    "\n",
    "  # Get the End position\n",
    "  original_text_end_position = None\n",
    "  if end_position in tokenized_non_space_to_space_map:\n",
    "    non_space_end_position = tokenized_non_space_to_space_map[end_position]\n",
    "    if non_space_end_position in original_non_space_to_space_map:\n",
    "      original_text_end_position = original_non_space_to_space_map[non_space_end_position]\n",
    "\n",
    "  # Check if the end position is None\n",
    "  if original_text_end_position is None:\n",
    "    return original_text\n",
    "  \n",
    "  # Get the answer using start position and end position in the text\n",
    "  final_output_text = original_text[original_start_position:(original_text_end_position + 1)]\n",
    "  return final_output_text\n",
    "# Calculates the probability of the span found\n",
    "def compute_softmax_score(scores):\n",
    "  if not scores:\n",
    "    return []\n",
    "\n",
    "  maximum_softmax_score = None\n",
    "  for score in scores:\n",
    "    if maximum_softmax_score is None or score > maximum_softmax_score:\n",
    "      maximum_softmax_score = score\n",
    "\n",
    "  expected_scores = []\n",
    "  total_score_sum = 0.0\n",
    "  for score in scores:\n",
    "    x = math.exp(score - maximum_softmax_score)\n",
    "    expected_scores.append(x)\n",
    "    total_score_sum += x\n",
    "\n",
    "  probabilities = []\n",
    "  for score in expected_scores:\n",
    "    probabilities.append(score / total_score_sum) # Probability calculation using the softmax score\n",
    "  return probabilities\n",
    "\n",
    "# Removing punctuations, lowering texts and removing extra white spaces\n",
    "def normalize_answer1(s):\n",
    "    \n",
    "    # Remove articles from the text\n",
    "    def remove_articles(text):\n",
    "        regex = re.compile(r'\\b(a|an|the)\\b', re.UNICODE)\n",
    "        return re.sub(regex, ' ', text)\n",
    "    \n",
    "    # Remove white spaces from the text\n",
    "    def white_space_fix(text):\n",
    "        return ' '.join(text.split())\n",
    "\n",
    "    # Remove punctuations from the text\n",
    "    def remove_punc(text):\n",
    "        exclude = set(string.punctuation)\n",
    "        return ''.join(ch for ch in text if ch not in exclude)\n",
    "\n",
    "    # Lower the text characters\n",
    "    def lower(text):\n",
    "        return text.lower()\n",
    "\n",
    "    return white_space_fix(remove_articles(remove_punc(lower(s))))\n",
    "\n",
    "# Check if the predictions are numbers or boolean values then set those to string equivalent\n",
    "def confirm_predictions(json_best_predictions):\n",
    "  # Number strings that will be used to represent numbers in the answers instead of actual numbers\n",
    "  subs = ['one', 'two', 'three','four','five','six','seven','eight','nine','ten','eleven','twelve','true','false']\n",
    "  original = json_best_predictions[0]['text']\n",
    "  if len(original) < 2:\n",
    "    for e in json_best_predictions[1:]:\n",
    "      if normalize_answer1(e['text']) in subs:\n",
    "        return e['text']\n",
    "    return 'unknown'\n",
    "  return original\n",
    "# Function to Predict answers and write those predictions to predictions file \n",
    "def predict_answers(test_samples, test_sample_features, results_for_predictions, best_size,\n",
    "                  maximum_answer_length, low_case, op_pred_file, v_log,\n",
    "                  null_score_threshold):\n",
    "  \n",
    "  ex_index_to_feat_index = collections.defaultdict(list)\n",
    "  \n",
    "  # Create the dictionary of all the features in test features keeping feature index as key\n",
    "  for feature in test_sample_features:\n",
    "    ex_index_to_feat_index[feature.example_index].append(feature)\n",
    " \n",
    "  ids_for_results = {}\n",
    "  for result in results_for_predictions:\n",
    "    ids_for_results[result.unique_id] = result\n",
    "   \n",
    "  # Naming the tuples for predictions\n",
    "  Preliminary_Predictions = collections.namedtuple(\n",
    "      \"Preliminary_Predictions\", [\n",
    "                           \"feature_index\",\n",
    "                           \"start_index\",\n",
    "                           \"end_index\",\n",
    "                           \"start_logit\",\n",
    "                           \"end_logit\",\n",
    "                           \"class_logit\",\n",
    "                           \"class_index\",\n",
    "      ])\n",
    "  \n",
    "  complete_predictions = []\n",
    "  best_n_predictions_json = collections.OrderedDict() #in this case best 30 predictions\n",
    "  prediction_scores_json = collections.OrderedDict()\n",
    "  \n",
    "  for (example_index, example) in enumerate(\n",
    "      tqdm(test_samples, desc=\"Predicting...\")):\n",
    "    features = ex_index_to_feat_index[example_index]\n",
    "     \n",
    "    preliminary_predictions = []\n",
    "\n",
    "    part_preliminary_predictions = []\n",
    "\n",
    "    # Indices initialization\n",
    "    score_of_answer_yes, score_of_answer_no, score_span, score_of_no_answer = -float('INF'), -float('INF'), -float('INF'), float('INF')\n",
    "\n",
    "    \n",
    "    minimum_no_answer_feature_index, maximum_yes_feature_index, maximum_no_feature_index, maximum_span_feature_index = 0, 0, 0, 0\n",
    "    max_span_start_indexes, max_span_end_indexes = [], []\n",
    "     \n",
    "    # get the best start and end indices\n",
    "    for (feature_index, feature) in enumerate(features):\n",
    "       \n",
    "      result = ids_for_results[feature.unique_id]\n",
    "      # check the score for each class and determine the output yes, no, or span, or unknown \n",
    "      feature_yes_score, feature_no_score, feature_noanswer_score, feature_span_score = result.cls_logits \n",
    "       \n",
    "      if feature_noanswer_score < score_of_no_answer:\n",
    "        score_of_no_answer = feature_noanswer_score\n",
    "        minimum_no_answer_feature_index = feature_index\n",
    "      if feature_yes_score > score_of_answer_yes:\n",
    "        score_of_answer_yes = feature_yes_score\n",
    "        maximum_yes_feature_index = feature_index\n",
    "      if feature_no_score > score_of_answer_no:\n",
    "        score_of_answer_no = feature_no_score\n",
    "        maximum_no_feature_index = feature_index\n",
    "      # Here hasn't assign the correct class yet\n",
    "      if feature_span_score > score_span:\n",
    "        score_span = feature_span_score\n",
    "        maximum_span_feature_index = feature_index\n",
    "        start_indices = compute_best_indices(result.start_logits,\n",
    "                                                  best_size)\n",
    "        end_indices = compute_best_indices(result.end_logits, best_size)\n",
    "        maximum_span_start_indices, maximum_span_end_indices = start_indices, end_indices\n",
    "      \n",
    "         \n",
    "    \n",
    "    preliminary_predictions.append(\n",
    "        Preliminary_Predictions(feature_index=minimum_no_answer_feature_index,\n",
    "                                start_index=0,\n",
    "                                end_index=0,\n",
    "                                start_logit=-float('INF'),\n",
    "                                end_logit=-float('INF'),\n",
    "                                class_logit=score_of_no_answer,\n",
    "                                class_index=2))\n",
    "    preliminary_predictions.append(\n",
    "              Preliminary_Predictions(feature_index=maximum_yes_feature_index,\n",
    "                                start_index=0,\n",
    "                                end_index=0,\n",
    "                                start_logit=-float('INF'),\n",
    "                                end_logit=-float('INF'),\n",
    "                                class_logit=score_of_answer_yes,\n",
    "                                class_index=0))\n",
    "    preliminary_predictions.append(\n",
    "              Preliminary_Predictions(feature_index=maximum_no_feature_index,\n",
    "                                start_index=0,\n",
    "                                end_index=0,\n",
    "                                start_logit=-float('INF'),\n",
    "                                end_logit=-float('INF'),\n",
    "                                class_logit=score_of_answer_no,\n",
    "                                class_index=1))\n",
    "    preliminary_predictions.append(\n",
    "              Preliminary_Predictions(feature_index=maximum_span_feature_index,\n",
    "                                start_index=0,\n",
    "                                end_index=0,\n",
    "                                start_logit=-float('INF'),\n",
    "                                end_logit=-float('INF'),\n",
    "                                class_logit=score_span,\n",
    "                                class_index=3))\n",
    "   \n",
    "    feature = features[maximum_span_feature_index]\n",
    "    for start_index in maximum_span_start_indices:\n",
    "      for end_index in maximum_span_end_indices:\n",
    "        \n",
    "        if start_index >= len(feature.tokens):\n",
    "          continue\n",
    "        if end_index >= len(feature.tokens):\n",
    "          continue\n",
    "        if start_index not in feature.token_to_origin_mapping:\n",
    "          continue\n",
    "        if end_index not in feature.token_to_origin_mapping:\n",
    "          continue\n",
    "        if not feature.token_max_context.get(start_index, False):\n",
    "          continue\n",
    "        if end_index < start_index:\n",
    "          continue\n",
    "        length = end_index - start_index + 1\n",
    "        if length > maximum_answer_length:\n",
    "          continue\n",
    "        \n",
    "        part_preliminary_predictions.append(\n",
    "                      Preliminary_Predictions(\n",
    "                          feature_index=maximum_span_feature_index,\n",
    "                          start_index=start_index,\n",
    "                          end_index=end_index,\n",
    "                          start_logit=ids_for_results[\n",
    "                              feature.unique_id].start_logits[start_index],\n",
    "                          end_logit=ids_for_results[\n",
    "                              feature.unique_id].end_logits[end_index],\n",
    "                          class_logit=score_span,\n",
    "                          class_index=3))\n",
    "    ##this is to sort the largest score value for start and end pair    \n",
    "    part_preliminary_predictions = sorted(\n",
    "              part_preliminary_predictions,\n",
    "              key=lambda p: p.start_logit + p.end_logit,\n",
    "              reverse=True)\n",
    "    ##this is to sort the largest score value for class \n",
    "    preliminary_predictions = sorted(preliminary_predictions,\n",
    "                                      key=lambda p: p.class_logit,\n",
    "                                      reverse=True)\n",
    "    \n",
    "    Best_Predictions = collections.namedtuple(  \n",
    "              \"Best_Predictions\",\n",
    "              [\"text\", \"start_logit\", \"end_logit\", \"class_logit\", \"class_index\"])\n",
    "    \n",
    "    known_predictions = {}\n",
    "    best = []\n",
    "    class_rank = []\n",
    "    for prediction in part_preliminary_predictions:\n",
    "      if len(best) >= best_size:\n",
    "        break\n",
    "      feature = features[prediction.feature_index]\n",
    "      if prediction.class_index == 3:\n",
    "        tokenized_tokens = feature.tokens[prediction.start_index:(prediction.end_index + 1)]\n",
    "        original_document_start = feature.token_to_origin_mapping[prediction.start_index]\n",
    "        original_document_end = feature.token_to_origin_mapping[prediction.end_index]\n",
    "        original_tokens = example.document_tokens[original_document_start:(original_document_end + 1)]\n",
    "        \n",
    "        tokenized_text = \" \".join(tokenized_tokens)\n",
    "\n",
    "        tokenized_text = tokenized_text.replace(\" ##\", \"\")\n",
    "        tokenized_text = tokenized_text.replace(\"##\", \"\")\n",
    "\n",
    "        tokenized_text = tokenized_text.strip()\n",
    "        tokenized_text = \" \".join(tokenized_text.split())\n",
    "        original_text = \" \".join(original_tokens)\n",
    "\n",
    "        final_output_text = output_final_answer_text(tokenized_text, original_text, low_case, v_log)\n",
    "         \n",
    "        if final_output_text in known_predictions:\n",
    "          continue\n",
    "\n",
    "        known_predictions[final_output_text] = True\n",
    "        best.append(\n",
    "                      Best_Predictions(text=final_output_text,\n",
    "                                      start_logit=prediction.start_logit,\n",
    "                                      end_logit=prediction.end_logit,\n",
    "                                      class_logit=prediction.class_logit,\n",
    "                                      class_index=prediction.class_index))\n",
    "    \n",
    "    # Writing the approriate answers in predictions which will be written to json file\n",
    "    if not best or len(best) < 1: \n",
    "      best.append(\n",
    "                  Best_Predictions(text=\"unknown\",\n",
    "                                  start_logit=-float('INF'),\n",
    "                                  end_logit=-float('INF'),\n",
    "                                  class_logit=score_span,\n",
    "                                  class_index=3))\n",
    "    for prediction in preliminary_predictions:\n",
    "      if prediction.class_index == 3:\n",
    "        final_output_text = best[0].text\n",
    "        class_rank.append(\n",
    "                      Best_Predictions(text=final_output_text,\n",
    "                                      start_logit=best[0].start_logit,\n",
    "                                      end_logit=best[0].end_logit,\n",
    "                                      class_logit=prediction.class_logit,\n",
    "                                      class_index=prediction.class_index))\n",
    "      elif prediction.class_index == 0:\n",
    "        final_output_text = \"yes\"\n",
    "        class_rank.append(\n",
    "                      Best_Predictions(text=final_output_text,\n",
    "                                      start_logit=-float('INF'),\n",
    "                                      end_logit=-float('INF'),\n",
    "                                      class_logit=prediction.class_logit,\n",
    "                                      class_index=prediction.class_index))\n",
    "      elif prediction.class_index == 1:\n",
    "                  final_output_text = \"no\"\n",
    "                  class_rank.append(\n",
    "                      Best_Predictions(text=final_output_text,\n",
    "                                      start_logit=-float('INF'),\n",
    "                                      end_logit=-float('INF'),\n",
    "                                      class_logit=prediction.class_logit,\n",
    "                                      class_index=prediction.class_index))\n",
    "      elif prediction.class_index == 2:\n",
    "                  final_output_text = \"unknown\"\n",
    "                  class_rank.append(\n",
    "                      Best_Predictions(text=final_output_text,\n",
    "                                      start_logit=-float('INF'),\n",
    "                                      end_logit=-float('INF'),\n",
    "                                      class_logit=prediction.class_logit,\n",
    "                                      class_index=prediction.class_index))\n",
    "                  \n",
    "    assert len(best) >= 1\n",
    "\n",
    "    total_scores = []\n",
    "    class_scores = []\n",
    "    for item in best:\n",
    "      total_scores.append(item.start_logit + item.end_logit)\n",
    "    for rank in class_rank:\n",
    "      class_scores.append(rank.class_logit)\n",
    "    \n",
    "    # calculate Softmax\n",
    "    span_probabilities = compute_softmax_score(total_scores)\n",
    "    class_probabilities = compute_softmax_score(class_scores)\n",
    "    best_predictions_json = []\n",
    "\n",
    "    current_rank, current_probabilities, current_scores = (\n",
    "        best, span_probabilities,\n",
    "        total_scores) if class_rank[0].class_index == 3 and len(best) > 1 else (\n",
    "            class_rank, class_probabilities, class_scores)\n",
    "    \n",
    "    \n",
    "    # Store the answer text, probability and score for each entry\n",
    "    for i, entry in enumerate(current_rank): \n",
    "      predicted_outputs = collections.OrderedDict()\n",
    "      predicted_outputs[\"text\"] = entry.text\n",
    "      predicted_outputs[\"probability\"] = current_probabilities[i]\n",
    "      predicted_outputs[\"score\"] = current_scores[i]\n",
    "      best_predictions_json.append(predicted_outputs)\n",
    "\n",
    "    assert len(best_predictions_json) >= 1\n",
    "\n",
    "    _id, _turn_id = example.question_answer_id.split()\n",
    "    complete_predictions.append({'id': _id, 'turn_id': int(_turn_id), 'answer': confirm_predictions(best_predictions_json)})\n",
    "    best_n_predictions_json[example.question_answer_id] = best_predictions_json\n",
    "\n",
    "  # Write the prediction files\n",
    "  with open(op_pred_file, \"w\") as writer:\n",
    "        writer.write(json.dumps(complete_predictions, indent=4) + \"\\n\")\n",
    "  \n",
    "  with open(output_nbest_file, \"w\") as writer:\n",
    "        writer.write(json.dumps(best_n_predictions_json, indent=4) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3298,
     "status": "ok",
     "timestamp": 1619446692600,
     "user": {
      "displayName": "Ning Zhang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhRCnmT8mmairzuShAibDId7kDGmrCXjp8yIjrCOw=s64",
      "userId": "12536691088853738123"
     },
     "user_tz": -480
    },
    "id": "HxhzcNKEAw1Z",
    "outputId": "9a6f63b1-ab83-47bf-fb3e-1598f9b91ed6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting...: 100%|██████████| 12/12 [00:00<00:00, 225.89it/s]\n"
     ]
    }
   ],
   "source": [
    "# Call to predict answers functions to write them to predictions file\n",
    "predict_answers(testing_samples, testing_features, results_for_predictions, 20, 30, True, \n",
    "                  op_pred_file, True, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2624,
     "status": "ok",
     "timestamp": 1619446692600,
     "user": {
      "displayName": "Ning Zhang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhRCnmT8mmairzuShAibDId7kDGmrCXjp8yIjrCOw=s64",
      "userId": "12536691088853738123"
     },
     "user_tz": -480
    },
    "id": "LDWdmf71f8sI",
    "outputId": "37890fc3-b80e-4568-c22d-5409e6932df8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing prediction for 3i02618ya06g9pi2dcnttyux9nopu3 and turn_id: 1\n",
      "Missing prediction for 3i02618ya06g9pi2dcnttyux9nopu3 and turn_id: 2\n",
      "Missing prediction for 3i02618ya06g9pi2dcnttyux9nopu3 and turn_id: 3\n",
      "Missing prediction for 3i02618ya06g9pi2dcnttyux9nopu3 and turn_id: 4\n",
      "Missing prediction for 3i02618ya06g9pi2dcnttyux9nopu3 and turn_id: 5\n",
      "Missing prediction for 3i02618ya06g9pi2dcnttyux9nopu3 and turn_id: 6\n",
      "Missing prediction for 3i02618ya06g9pi2dcnttyux9nopu3 and turn_id: 7\n",
      "Missing prediction for 3i02618ya06g9pi2dcnttyux9nopu3 and turn_id: 8\n",
      "Missing prediction for 3i02618ya06g9pi2dcnttyux9nopu3 and turn_id: 9\n",
      "Missing prediction for 3i02618ya06g9pi2dcnttyux9nopu3 and turn_id: 10\n",
      "Missing prediction for 3i02618ya06g9pi2dcnttyux9nopu3 and turn_id: 11\n",
      "Missing prediction for 3i02618ya06g9pi2dcnttyux9nopu3 and turn_id: 12\n",
      "Missing prediction for 3i02618ya06g9pi2dcnttyux9nopu3 and turn_id: 13\n",
      "Missing prediction for 3i02618ya06g9pi2dcnttyux9nopu3 and turn_id: 14\n",
      "Missing prediction for 3i02618ya06g9pi2dcnttyux9nopu3 and turn_id: 15\n",
      "Missing prediction for 3i02618ya06g9pi2dcnttyux9nopu3 and turn_id: 16\n",
      "Missing prediction for 3i02618ya06g9pi2dcnttyux9nopu3 and turn_id: 17\n",
      "Missing prediction for 3i02618ya06g9pi2dcnttyux9nopu3 and turn_id: 18\n",
      "Missing prediction for 3i02618ya06g9pi2dcnttyux9nopu3 and turn_id: 19\n",
      "Missing prediction for 3ixqg4fa2tygl3tpwwa12i2uf58b90 and turn_id: 1\n",
      "Missing prediction for 3ixqg4fa2tygl3tpwwa12i2uf58b90 and turn_id: 2\n",
      "Missing prediction for 3ixqg4fa2tygl3tpwwa12i2uf58b90 and turn_id: 3\n",
      "Missing prediction for 3ixqg4fa2tygl3tpwwa12i2uf58b90 and turn_id: 4\n",
      "Missing prediction for 3ixqg4fa2tygl3tpwwa12i2uf58b90 and turn_id: 5\n",
      "Missing prediction for 3ixqg4fa2tygl3tpwwa12i2uf58b90 and turn_id: 6\n",
      "Missing prediction for 3ixqg4fa2tygl3tpwwa12i2uf58b90 and turn_id: 7\n",
      "Missing prediction for 3ixqg4fa2tygl3tpwwa12i2uf58b90 and turn_id: 8\n",
      "Missing prediction for 3ixqg4fa2tygl3tpwwa12i2uf58b90 and turn_id: 9\n",
      "Missing prediction for 3ixqg4fa2tygl3tpwwa12i2uf58b90 and turn_id: 10\n",
      "Missing prediction for 3ixqg4fa2tygl3tpwwa12i2uf58b90 and turn_id: 11\n",
      "Missing prediction for 3ixqg4fa2tygl3tpwwa12i2uf58b90 and turn_id: 12\n",
      "{\n",
      "  \"children_stories\": {\n",
      "    \"em\": 25.0,\n",
      "    \"f1\": 25.0,\n",
      "    \"turns\": 12\n",
      "  },\n",
      "  \"literature\": {\n",
      "    \"em\": 0.0,\n",
      "    \"f1\": 0.0,\n",
      "    \"turns\": 0\n",
      "  },\n",
      "  \"mid-high_school\": {\n",
      "    \"em\": 0.0,\n",
      "    \"f1\": 0.0,\n",
      "    \"turns\": 19\n",
      "  },\n",
      "  \"news\": {\n",
      "    \"em\": 0.0,\n",
      "    \"f1\": 0.0,\n",
      "    \"turns\": 0\n",
      "  },\n",
      "  \"wikipedia\": {\n",
      "    \"em\": 0.0,\n",
      "    \"f1\": 0.0,\n",
      "    \"turns\": 12\n",
      "  },\n",
      "  \"reddit\": {\n",
      "    \"em\": 0.0,\n",
      "    \"f1\": 0.0,\n",
      "    \"turns\": 0\n",
      "  },\n",
      "  \"science\": {\n",
      "    \"em\": 0.0,\n",
      "    \"f1\": 0.0,\n",
      "    \"turns\": 0\n",
      "  },\n",
      "  \"in_domain\": {\n",
      "    \"em\": 7.0,\n",
      "    \"f1\": 7.0,\n",
      "    \"turns\": 43\n",
      "  },\n",
      "  \"out_domain\": {\n",
      "    \"em\": 0.0,\n",
      "    \"f1\": 0.0,\n",
      "    \"turns\": 0\n",
      "  },\n",
      "  \"overall\": {\n",
      "    \"em\": 7.0,\n",
      "    \"f1\": 7.0,\n",
      "    \"turns\": 43\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!python3 evaluate.py --data-file data/coqa-dev-v1.0.json --pred-file outputs/Output_Preds_albert_base_8_2linear.json\n",
    "#!python3 evaluate.py --data-file data/coqa-dev-v1.0_.json --pred-file outputs/Output_Preds_roberta.json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n_d2tP70IKT4"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMhHFF1QwBmePStxw1R4mYA",
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "albert_base_2 linear layer with relu.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "145163cbadd1442cb1b0c6e20d3f8a9f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "22da6a5b2dae429a9c564d522f4a79bc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b269b04f3e404212a3610b3de84dc551",
       "IPY_MODEL_52d31e349bf94a55be076a420dfdbc76"
      ],
      "layout": "IPY_MODEL_9eb32b75218e43398d4cf9cc813788c9"
     }
    },
    "24d54066f4da4ae58cb541709e966b0c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2b54f5b605cd44629547a058bfa7738b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "3dfb6a36168c4a04aece60a336922b14": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "52d31e349bf94a55be076a420dfdbc76": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d5d1a8101793408b9ba243f302b1b000",
      "placeholder": "​",
      "style": "IPY_MODEL_24d54066f4da4ae58cb541709e966b0c",
      "value": " 760k/760k [00:12&lt;00:00, 58.9kB/s]"
     }
    },
    "7c92dbd6927141b1922bd067a02bc54b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_95f7f39cdc76466283d730fd73e9a0b1",
      "max": 1312669,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2b54f5b605cd44629547a058bfa7738b",
      "value": 1312669
     }
    },
    "95f7f39cdc76466283d730fd73e9a0b1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9eb32b75218e43398d4cf9cc813788c9": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ab880266879c4fb4b91427f81ba8e987": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "b269b04f3e404212a3610b3de84dc551": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dcd6887760e94121a38ca44a9d956861",
      "max": 760289,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ab880266879c4fb4b91427f81ba8e987",
      "value": 760289
     }
    },
    "d5d1a8101793408b9ba243f302b1b000": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dcd6887760e94121a38ca44a9d956861": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "eb5fd91c4b3840a68907f6d204c8c150": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ebbbe2d972a14ef9be1563219da7ad2e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7c92dbd6927141b1922bd067a02bc54b",
       "IPY_MODEL_febcc9aaa184403c9dd8bbb66242a458"
      ],
      "layout": "IPY_MODEL_145163cbadd1442cb1b0c6e20d3f8a9f"
     }
    },
    "febcc9aaa184403c9dd8bbb66242a458": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3dfb6a36168c4a04aece60a336922b14",
      "placeholder": "​",
      "style": "IPY_MODEL_eb5fd91c4b3840a68907f6d204c8c150",
      "value": " 1.31M/1.31M [00:03&lt;00:00, 344kB/s]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
